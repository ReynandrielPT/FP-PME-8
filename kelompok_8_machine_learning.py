# -*- coding: utf-8 -*-
"""Kelompok 8 - Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S4ApLdsQx5dB3o_e4dis-sAdgi5A34Be
"""

!pip install catboost

import warnings
warnings.filterwarnings('ignore')
import logging, os
logging.getLogger('lightgbm').setLevel(logging.ERROR)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from imblearn.over_sampling import RandomOverSampler, SMOTE

BALANCERS = {'None': None, 'ROS': RandomOverSampler(random_state=40), 'SMOTE': SMOTE(random_state=40)}
MODELS = {
    'Decision Tree': DecisionTreeClassifier(random_state=40),
    'Random Forest': RandomForestClassifier(random_state=40),
    'KNN': KNeighborsClassifier(),
    'Logistic Regression': LogisticRegression(max_iter=300, random_state=40),
    'Gaussian NB': GaussianNB(),
    'SVM': SVC(probability=True, random_state=40),
    'ANN': MLPClassifier(max_iter=300, random_state=40),
    'CatBoost': CatBoostClassifier(verbose=0, random_state=40),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', verbosity=0, random_state=40),
    'LightGBM': LGBMClassifier(random_state=40, verbose=-1)
}


plots_dir = 'plots'
results_dir = 'results'
os.makedirs(plots_dir, exist_ok=True)
os.makedirs(results_dir, exist_ok=True)

df = pd.read_csv('enhanced_anxiety_dataset.csv')
df['Stress_Level_numeric'] = df['Stress Level (1-10)']
stress_col = 'Stress_Level_numeric'

df.rename(columns={'Anxiety Level (1-10)': 'Anxiety_Level'}, inplace=True)
df['Anxiety_Category'] = df['Anxiety_Level'].apply(
    lambda x: 'Very Low' if x<=2 else 'Low' if x<=4 else 'Medium' if x<=6 else 'High' if x<=8 else 'Very High'
)
target_le = LabelEncoder()
y = target_le.fit_transform(df['Anxiety_Category'])

# ----- EDA -----
print(df.head())
print(df.describe(include='all'))
df.head().to_csv(os.path.join(results_dir, 'eda_head.csv'), index=False)
df.describe(include='all').to_csv(os.path.join(results_dir, 'eda_describe.csv'))

# ----- Preprocessing -----
base_cols = ['Age','Gender','Occupation','Sleep Hours','Physical Activity (hrs/week)',
             'Caffeine Intake (mg/day)','Alcohol Consumption (drinks/week)','Smoking',
             'Family History of Anxiety','Heart Rate (bpm)','Breathing Rate (breaths/min)',
             'Sweating Level (1-5)','Dizziness','Medication','Therapy Sessions (per month)',
             'Recent Major Life Event','Diet Quality (1-10)', stress_col]

X = df[base_cols].copy()
for col in base_cols:
    if X[col].dtype in [np.int64, np.float64]:
        X[col].fillna(X[col].mean(), inplace=True)
    else:
        X[col].fillna(X[col].mode()[0], inplace=True)

X_train_orig, X_test, y_train_orig, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

categorical_cols = [c for c in base_cols if X[c].dtype == object]
encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    X_train_orig[col] = le.fit_transform(X_train_orig[col])
    X_test[col]       = le.transform(X_test[col])
    encoders[col]     = le

X_train_orig.columns = X_train_orig.columns.str.replace(' ', '_').str.replace(r'[()/\-]', '_', regex=True)
X_test.columns       = X_test.columns.str.replace(' ', '_').str.replace(r'[()/\-]', '_', regex=True)

scaler = StandardScaler()
num_cols = X_train_orig.select_dtypes(include=['int64','float64']).columns
X_train_orig[num_cols] = scaler.fit_transform(X_train_orig[num_cols])
X_test[num_cols]       = scaler.transform(X_test[num_cols])


# ----- Training & Evaluation -----
results = []
for bal_name, bal in BALANCERS.items():
    X_train, y_train = X_train_orig.copy(), y_train_orig.copy()
    if bal is not None:
        X_train, y_train = bal.fit_resample(X_train, y_train)
        print(f"After {bal_name}, train shape: {X_train.shape}")
    for name, model in MODELS.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        print(f"-- {name} ({bal_name}) --\nAccuracy: {acc:.3f}, F1 Score: {f1:.3f}")
        print(classification_report(y_test, y_pred, target_names=target_le.classes_))
        cm = confusion_matrix(y_test, y_pred)
        pd.DataFrame(cm, index=target_le.classes_, columns=target_le.classes_).to_csv(
            os.path.join(results_dir, f"cm_{name}_{bal_name}.csv"))
        plt.figure()
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_le.classes_, yticklabels=target_le.classes_)
        plt.title(f"{name} ({bal_name}) Confusion Matrix")
        plt.savefig(os.path.join(plots_dir, f"{name}_{bal_name}_confusion_matrix.png"), bbox_inches='tight')
        plt.show()

        results.append({'Balancer': bal_name, 'Model': name, 'Accuracy': acc, 'F1': f1})

res_df = pd.DataFrame(results)
res_df.to_csv(os.path.join(results_dir, 'model_metrics.csv'), index=False)

for metric in ['Accuracy','F1']:
    plt.figure(figsize=(10,6))
    sns.barplot(x='Model', y=metric, hue='Balancer', data=res_df)
    plt.title(f'Model {metric} Comparison')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(os.path.join(plots_dir, f"model_{metric.lower()}_comparison.png"), bbox_inches='tight')
    plt.show()

best_acc = res_df.loc[res_df['Accuracy'].idxmax()]
best_f1 = res_df.loc[res_df['F1'].idxmax()]
print(f"Best Accuracy: {best_acc['Model']} - {best_acc['Accuracy']:.3f} ({best_acc['Balancer']})")
print(f"Best F1 Score: {best_f1['Model']} - {best_f1['F1']:.3f} ({best_f1['Balancer']})")